{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e7be9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import albumentations\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFile\n",
    "import string\n",
    "import os   \n",
    "from config import  DATA_DIR, BATCH_SIZE, IMAGE_WIDTH, IMAGE_HEIGHT, EPOCHS, LEARNING_RATE, NUM_WORKERS, DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33b9a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "class dataset:\n",
    "    def __init__(self, image_path, targets, resize=None):\n",
    "        self.image_path = image_path\n",
    "        self.targets = targets\n",
    "        self.resize = resize\n",
    "        self.aug = albumentations.Compose([albumentations.Normalize(always_apply=True)])\n",
    "        \n",
    "        # mapping huruf ke angka\n",
    "        alphabet = string.ascii_lowercase   # 'abcdefghijklmnopqrstuvwxyz'\n",
    "        self.char2idx = {ch: idx+1 for idx, ch in enumerate(alphabet)}  # mulai dari 1\n",
    "        self.char2idx[\"<pad>\"] = 0  # buat padding jika perlu\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_path)\n",
    "    \n",
    "    def text_to_seq(self, text):\n",
    "        \"\"\"Ubah string label jadi list angka huruf per huruf\"\"\"\n",
    "        return [self.char2idx[c] for c in text.lower() if c in self.char2idx]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        # ambil gambar\n",
    "        image = Image.open(self.image_path[item]).convert(\"RGB\")\n",
    "        targets = self.targets[item]   # string kata, misal \"kucing\"\n",
    "\n",
    "        if self.resize is not None:\n",
    "            image = image.resize((self.resize[0], self.resize[1]), resample=Image.BILINEAR)\n",
    "\n",
    "        image = np.array(image)\n",
    "        augmented = self.aug(image=image)\n",
    "        image = augmented['image']\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "\n",
    "        # ubah kata jadi list angka\n",
    "        target_seq = self.text_to_seq(targets)\n",
    "\n",
    "        return {\n",
    "            \"images\": torch.tensor(image, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(target_seq, dtype=torch.long),   # urutan huruf dalam bentuk tensor\n",
    "            \"target_length\": torch.tensor(len(target_seq), dtype=torch.long)  # panjang kata\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10021d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"labels.csv\")\n",
    "df[\"filepath\"] = df[\"filename\"].apply(lambda x: f\"{DATA_DIR}/{x}\")\n",
    "df.to_csv(\"labels_with_path.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c43baa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"labels_with_path.csv\")\n",
    "image_paths = df[\"filepath\"].tolist()\n",
    "targets = df[\"label\"].tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e395c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_0.png</td>\n",
       "      <td>xjdv</td>\n",
       "      <td>dataset_pil/img_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_1.png</td>\n",
       "      <td>nwxff</td>\n",
       "      <td>dataset_pil/img_1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_2.png</td>\n",
       "      <td>wugb</td>\n",
       "      <td>dataset_pil/img_2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_3.png</td>\n",
       "      <td>omapsdso</td>\n",
       "      <td>dataset_pil/img_3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_4.png</td>\n",
       "      <td>ehjcxhg</td>\n",
       "      <td>dataset_pil/img_4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>img_79995.png</td>\n",
       "      <td>mrokrhpft</td>\n",
       "      <td>dataset_pil/img_79995.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>img_79996.png</td>\n",
       "      <td>ntuvxev</td>\n",
       "      <td>dataset_pil/img_79996.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>img_79997.png</td>\n",
       "      <td>uybeusnx</td>\n",
       "      <td>dataset_pil/img_79997.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>img_79998.png</td>\n",
       "      <td>rqtju</td>\n",
       "      <td>dataset_pil/img_79998.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>img_79999.png</td>\n",
       "      <td>fqxh</td>\n",
       "      <td>dataset_pil/img_79999.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename      label                   filepath\n",
       "0          img_0.png       xjdv      dataset_pil/img_0.png\n",
       "1          img_1.png      nwxff      dataset_pil/img_1.png\n",
       "2          img_2.png       wugb      dataset_pil/img_2.png\n",
       "3          img_3.png   omapsdso      dataset_pil/img_3.png\n",
       "4          img_4.png    ehjcxhg      dataset_pil/img_4.png\n",
       "...              ...        ...                        ...\n",
       "79995  img_79995.png  mrokrhpft  dataset_pil/img_79995.png\n",
       "79996  img_79996.png    ntuvxev  dataset_pil/img_79996.png\n",
       "79997  img_79997.png   uybeusnx  dataset_pil/img_79997.png\n",
       "79998  img_79998.png      rqtju  dataset_pil/img_79998.png\n",
       "79999  img_79999.png       fqxh  dataset_pil/img_79999.png\n",
       "\n",
       "[80000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7527666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset(image_path=image_paths, targets=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93773882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 80, 300])\n",
      "tensor([24, 10,  4, 22])\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[0]\n",
    "print(sample[\"images\"].shape)\n",
    "print(sample[\"targets\"])\n",
    "print(sample[\"target_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6ed5de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec297c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d7adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2874a80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331b40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56df09da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0db916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864256ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321b4e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5cefb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd04f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
